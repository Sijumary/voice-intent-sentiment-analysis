# voice-intent-sentiment-analysis
# voice-intent-sentiment-analyzer

A step-by-step GitHub-ready project scaffold to analyze call / voice recordings using a voice LLM (e.g., Gemini Voice). The project transcribes audio, performs speaker diarization (optional), and runs an intent/tone/sentiment extraction pipeline producing structured JSON and a small dashboard.

---

## What you'll get in this repo

* A clear file structure and README
* FastAPI backend with endpoints to upload audio and return analysis
* `services/` modules: audio preprocessing, transcription adapter, analysis adapter (calls LLM), postprocessing
* Example client script and minimal React UI (optional) to play recordings and view analysis
* Dockerfile and GitHub Actions CI for linting and tests
* Sample audio and test data

---

## Repo file tree (suggested)

```
voice-intent-sentiment-analyzer/
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ pyproject.toml (or requirements.txt)
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py            # FastAPI app
â”‚   â”œâ”€â”€ api.py             # endpoints
â”‚   â”œâ”€â”€ config.py          # env vars and config
â”‚   â”œâ”€â”€ models.py          # pydantic response/request models
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ audio.py       # audio processing helpers
â”‚   â”‚   â”œâ”€â”€ transcribe.py  # transcription adapter
â”‚   â”‚   â”œâ”€â”€ diarize.py     # speaker diarization (optional)
â”‚   â”‚   â””â”€â”€ analyze.py     # call to Gemini LLM for intent/tone/sentiment
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ fileio.py
â”œâ”€â”€ client/
â”‚   â”œâ”€â”€ example_client.py  # CLI example to call the API
â”‚   â””â”€â”€ small_web_ui/      # optional React app
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_transcribe.py
â”‚   â””â”€â”€ test_analyze.py
â””â”€â”€ samples/
    â”œâ”€â”€ sample_calls/
    â”‚   â””â”€â”€ sample1.wav
    â””â”€â”€ expected_output.json
```

---

## High-level steps (what this scaffold covers)

1. Install dependencies and set environment variables
2. Start FastAPI server
3. Upload / POST an audio file to `/analyze` endpoint
4. Server preprocesses audio (normalize, convert to wav, resample)
5. Transcription service returns text + timestamps
6. (Optional) Diarization to split speakers
7. Analysis service calls Gemini (or chosen LLM) with audio transcript + timestamps + short instructions to extract intent, tone, sentiment, urgency, and summary
8. Postprocess and return a JSON analysis and small HTML viewer

---

## Detailed setup

### Prerequisites

* Python 3.10+
* ffmpeg installed and in PATH (for pydub / ffmpeg-python)
* (Optional) Node.js 18+ for the small UI
* API key for the voice LLM (e.g., GOOGLE_GENAI_API_KEY for Gemini)

# Install

Using `pip` and `requirements.txt` (or `pyproject.toml`):

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

---

## Security & costs notes

* LLM and transcription calls may incur costs â€” use small test keys and a budget while developing.
* Never commit API keys â€” use `.env` and repository secrets for CI.
* If processing PII/audio from customers, follow local privacy laws and store minimal data.

---

## ğŸš€ Quick Start (GitHub Ready)

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/<your-username>/voice-intent-sentiment-analyzer.git
cd voice-intent-sentiment-analyzer
```

### 2ï¸âƒ£ Create virtual environment (Windows-friendly)

```bash
python -m venv .venv
.venv\Scripts\activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure environment variables

Create a `.env` file:

```env
GENAI_API_KEY=your_api_key_here
TRANSCRIBE_PROVIDER=mock
```

### 5ï¸âƒ£ Start the API server

```bash
python -m uvicorn app.main:app --reload --port 8000
```

### 6ï¸âƒ£ Analyze an audio file

```bash
curl -X POST http://127.0.0.1:8000/analyze \
  -H "Content-Type: multipart/form-data" \
  -F "audio=@samples/sample_calls/sample1.wav"
```

---

## ğŸ“¦ Example API Response

```json
{
  "sentiment": "negative",
  "tone": "frustrated",
  "intent": "cancel_subscription",
  "urgency": "high",
  "summary": "Customer wants to cancel due to dissatisfaction."
}
```

---

## ğŸ§± Architecture Overview

```
Client (curl / UI)
      â”‚
      â–¼
FastAPI API
      â”‚
      â”œâ”€â–º Audio Normalization (FFmpeg)
      â”œâ”€â–º Transcription Adapter (mock / Whisper / Gemini)
      â””â”€â–º LLM Analysis (intent, sentiment, tone)
      â”‚
      â–¼
Structured JSON Response
```

---


## ğŸ§  Resume Value

**Skills demonstrated:**

* FastAPI & REST APIs
* Audio processing (FFmpeg)
* LLM prompt engineering
* NLP classification (intent, sentiment)
* Production-ready project structure

---

## ğŸ“œ License

MIT

---

